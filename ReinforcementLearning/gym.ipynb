{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gym.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanstancin/RobotControlAlgorithms/blob/main/ReinforcementLearning/gym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUEXrxB-7Em0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61bbc7f-f985-42ce-e3cb-6084302228d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leugoswdBf0f"
      },
      "source": [
        "!cp /content/drive/MyDrive/RobotControl/reinf_learn.zip .\n",
        "!unzip reinf_learn.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dqgehH9I8hp"
      },
      "source": [
        "#!git clone https://github.com/xdralex/pioneer.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6SwFpWGJAvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7a8fcd-b04d-4995-a829-50d2dbeb4ba6"
      },
      "source": [
        "%cd /content/pioneer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pioneer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBa5bnSuJE2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa20dbd-7cb6-4639-cfe1-204a554e2798"
      },
      "source": [
        "!pip install -r requirements.txt "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.8.9)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.8.1+cu101)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.4.1)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (0.17.3)\n",
            "Collecting ray[debug]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/14/15d0f0aec20a4674a996429160565a071688f27f49f789327ebed8188ffb/ray-1.2.0-cp37-cp37m-manylinux2014_x86_64.whl (47.5MB)\n",
            "\u001b[K     |████████████████████████████████| 47.5MB 128kB/s \n",
            "\u001b[33m  WARNING: ray 1.2.0 does not provide the extra 'debug'\u001b[0m\n",
            "\u001b[?25hCollecting pybullet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/f0/cb894ec9fcd13859e5e27b9b58612f917e14fededccf4681f7aa70b63265/pybullet-3.1.2-cp37-cp37m-manylinux1_x86_64.whl (89.3MB)\n",
            "\u001b[K     |████████████████████████████████| 89.3MB 81kB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (2.23.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (4.1.2.30)\n",
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Collecting lz4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/52/151c815a486290608e4dc6699a0cfd74141dc5191f8fe928e7d1b28b569e/lz4-3.1.3-cp37-cp37m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.32.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]->-r requirements.txt (line 14)) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]->-r requirements.txt (line 14)) (1.3.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]->-r requirements.txt (line 14)) (0.2.6)\n",
            "Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]->-r requirements.txt (line 14)) (7.1.2)\n",
            "Collecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.1MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/a6/52515fe345fad06a567feb0ee3841bface31f00e1e0dcd401aa16b3fc648/py_spy-0.3.5-py2.py3-none-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[debug]->-r requirements.txt (line 15)) (0.10.1)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[debug]->-r requirements.txt (line 15)) (3.0.12)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.3MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[debug]->-r requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[debug]->-r requirements.txt (line 15)) (1.0.2)\n",
            "Collecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/d6/b952f11b29c3a0cbec5620de3c4260cecd8c4329d83e91587edb48691e15/opencensus-0.7.12-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 57.2MB/s \n",
            "\u001b[?25hCollecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 22)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 22)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 22)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 22)) (1.24.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 12)) (3.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]->-r requirements.txt (line 14)) (0.16.0)\n",
            "Collecting async-timeout\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/33/290cea35b09c80b4634773ad5572a8030a87b5d39736719f698f521d2a13/hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.5MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[debug]->-r requirements.txt (line 15)) (20.3.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 50.7MB/s \n",
            "\u001b[?25hCollecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[debug]->-r requirements.txt (line 15)) (1.26.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[debug]->-r requirements.txt (line 15)) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[debug]->-r requirements.txt (line 15)) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 12)) (3.1.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[debug]->-r requirements.txt (line 15)) (20.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[debug]->-r requirements.txt (line 15)) (1.53.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray[debug]->-r requirements.txt (line 15)) (2.4.7)\n",
            "Building wheels for collected packages: gputil, gpustat\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=1607e03c054e888746914929ed3700cf267cbde07b63b051ca70d3c4d5a0d440\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp37-none-any.whl size=12621 sha256=32b698429752ac3d6438230acf857dd6619c5ac316f76c99e82c3c86f21f8c50\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "Successfully built gputil gpustat\n",
            "Installing collected packages: async-timeout, hiredis, aioredis, redis, py-spy, multidict, yarl, aiohttp, aiohttp-cors, colorful, colorama, opencensus-context, opencensus, blessings, gpustat, ray, pybullet, gputil, lz4\n",
            "Successfully installed aiohttp-3.7.4.post0 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 gpustat-0.6.0 gputil-1.4.0 hiredis-2.0.0 lz4-3.1.3 multidict-5.1.0 opencensus-0.7.12 opencensus-context-0.1.2 py-spy-0.3.5 pybullet-3.1.2 ray-1.2.0 redis-3.5.3 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGpF9edXNKSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdac394-e002-4ddc-e8f5-4b82b95a2eba"
      },
      "source": [
        "!pip install tensorboardX "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 20kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 40kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 61kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 81kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 92kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 102kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3eGLI9BYPuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7956b4-5a72-4ea8-9c1b-cd28c4a06c9b"
      },
      "source": [
        "!pip install mujoco_py==2.0.2.8\n",
        "# save checkpoints on cloud!!!!!!!!!!!!!"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mujoco_py==2.0.2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/f8/1c2840d5ed717ac612aba2879dc1ce548451be6e4d32a7fc7c549c127119/mujoco_py-2.0.2.8-py3-none-any.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco_py==2.0.2.8) (0.29.22)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco_py==2.0.2.8) (1.14.5)\n",
            "Collecting fasteners~=0.15\n",
            "  Downloading https://files.pythonhosted.org/packages/78/20/c862d765287e9e8b29f826749ebae8775bdca50b2cb2ca079346d5fbfd76/fasteners-0.16-py2.py3-none-any.whl\n",
            "Collecting glfw>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/d7/79c091c877493de7f8286ed62c77bf0f2c51105656073846b2326021b524/glfw-2.1.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from mujoco_py==2.0.2.8) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from mujoco_py==2.0.2.8) (1.19.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco_py==2.0.2.8) (2.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners~=0.15->mujoco_py==2.0.2.8) (1.15.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio>=2.1.2->mujoco_py==2.0.2.8) (7.1.2)\n",
            "Installing collected packages: fasteners, glfw, mujoco-py\n",
            "Successfully installed fasteners-0.16 glfw-2.1.0 mujoco-py-2.0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky3F66MaJOj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c15eb92-e365-4390-9859-b735001b9744"
      },
      "source": [
        "!python3 cli.py pioneer-train-kinem -e 'exp' --num-workers 1 -n 1024"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pybullet build time: Apr  6 2021 03:40:09\n",
            "2021-04-16 04:47:14,002 WARNING  [tensorflow] - From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "== Status ==\n",
            "Memory usage on this node: 1.5/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 1/1024 (1 RUNNING)\n",
            "+----------------------------+----------+-------+-------------------------------------------+\n",
            "| Trial name                 | status   | loc   | entropy_coeff_schedule                    |\n",
            "|----------------------------+----------+-------+-------------------------------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  |       | [(0, 0.040703605516862085), (1000000, 0)] |\n",
            "+----------------------------+----------+-------+-------------------------------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m pybullet build time: Apr  6 2021 03:40:09\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m pybullet build time: Apr  6 2021 03:40:09\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m /usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:25,953\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:25,983\tINFO torch_policy.py:112 -- TorchPolicy running on CPU.\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m 2021-04-16 04:47:26,047\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m 2021-04-16 04:47:26,078\tINFO torch_policy.py:112 -- TorchPolicy running on CPU.\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m 2021-04-16 04:47:26,124\tINFO rollout_worker.py:1114 -- Built policy map: {'default_policy': <ray.rllib.policy.policy_template.PPOTorchPolicy object at 0x7f767272fd90>}\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m 2021-04-16 04:47:26,125\tINFO rollout_worker.py:1115 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f767053d210>}\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m 2021-04-16 04:47:26,125\tINFO rollout_worker.py:526 -- Built filter map: {'default_policy': ConcurrentMeanStdFilter((74,), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,163\tINFO rollout_worker.py:660 -- Generating sample batch of size 200\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,407\tINFO sampler.py:594 -- Raw obs from env: { 0: { 'agent0': np.ndarray((74,), dtype=float64, min=-3.142, max=4.006, mean=0.342)}}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,407\tINFO sampler.py:595 -- Info return from env: {0: {'agent0': None}}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,408\tWARNING deprecation.py:34 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,408\tINFO sampler.py:1058 -- Preprocessed obs: np.ndarray((74,), dtype=float64, min=-3.142, max=4.006, mean=0.342)\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,408\tINFO sampler.py:1063 -- Filtered obs: np.ndarray((74,), dtype=float64, min=0.0, max=0.0, mean=0.0)\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,411\tINFO sampler.py:1335 -- Inputs to compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                                   'env_id': 0,\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                                   'info': None,\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                                   'obs': np.ndarray((74,), dtype=float64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                                   'prev_action': None,\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                                   'prev_reward': 0.0,\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                                   'rnn_state': None},\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:26,416\tINFO sampler.py:1353 -- Outputs of compute_actions():\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m { 'default_policy': ( np.ndarray((1, 3), dtype=float32, min=0.08, max=3.862, mean=2.161),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                       [],\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                       { 'action_dist_inputs': np.ndarray((1, 6), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'action_logp': np.ndarray((1,), dtype=float32, min=-13.443, max=-13.443, mean=-13.443),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:44,375\tINFO simple_list_collector.py:674 -- Trajectory fragment after postprocess_trajectory():\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m { 'agent0': { 'data': { 'action_dist_inputs': np.ndarray((200, 6), dtype=float32, min=-0.013, max=0.012, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'action_logp': np.ndarray((200,), dtype=float32, min=-13.443, max=-2.808, mean=-4.309),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'actions': np.ndarray((200, 3), dtype=float32, min=-3.442, max=3.862, mean=0.045),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'advantages': np.ndarray((200,), dtype=float32, min=-1.364, max=84.784, mean=0.745),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'dones': np.ndarray((200,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'eps_id': np.ndarray((200,), dtype=int64, min=307735452.0, max=307735452.0, mean=307735452.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'new_obs': np.ndarray((200, 74), dtype=float32, min=-6.635, max=3.248, mean=0.083),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'obs': np.ndarray((200, 74), dtype=float32, min=-6.635, max=3.248, mean=0.082),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'rewards': np.ndarray((200,), dtype=float32, min=-0.066, max=84.244, mean=0.428),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'value_targets': np.ndarray((200,), dtype=float32, min=-0.255, max=84.784, mean=1.066),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m                         'vf_preds': np.ndarray((200,), dtype=float32, min=-1.369, max=1.328, mean=0.321)},\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m               'type': 'SampleBatch'}}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m 2021-04-16 04:47:44,379\tINFO rollout_worker.py:698 -- Completed sample batch:\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m { 'data': { 'action_dist_inputs': np.ndarray((200, 6), dtype=float32, min=-0.013, max=0.012, mean=-0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'action_logp': np.ndarray((200,), dtype=float32, min=-13.443, max=-2.808, mean=-4.309),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'actions': np.ndarray((200, 3), dtype=float32, min=-3.442, max=3.862, mean=0.045),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=-1.364, max=84.784, mean=0.745),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=307735452.0, max=307735452.0, mean=307735452.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'obs': np.ndarray((200, 74), dtype=float32, min=-6.635, max=3.248, mean=0.082),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=-0.255, max=84.784, mean=1.066),\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-1.369, max=1.328, mean=0.321)},\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m   'type': 'SampleBatch'}\n",
            "\u001b[2m\u001b[36m(pid=10960)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m 2021-04-16 04:50:01,779\tINFO rollout_worker.py:839 -- Training on concatenated sample batches:\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m { 'count': 128,\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m   'policy_batches': { 'default_policy': { 'data': { 'action_dist_inputs': np.ndarray((128, 6), dtype=float32, min=-0.018, max=0.014, mean=-0.001),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'action_logp': np.ndarray((128,), dtype=float32, min=-8.138, max=-2.778, mean=-4.092),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'actions': np.ndarray((128, 3), dtype=float32, min=-2.97, max=2.962, mean=0.002),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'advantages': np.ndarray((128,), dtype=float32, min=-1.131, max=0.932, mean=-0.14),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'agent_index': np.ndarray((128,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'eps_id': np.ndarray((128,), dtype=int64, min=68344015.0, max=1942197375.0, mean=860870500.914),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'obs': np.ndarray((128, 74), dtype=float32, min=-12.91, max=12.91, mean=-0.023),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'unroll_id': np.ndarray((128,), dtype=int64, min=0.0, max=47.0, mean=22.82),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'value_targets': np.ndarray((128,), dtype=float32, min=-4.983, max=3.271, mean=-0.637),\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                                     'vf_preds': np.ndarray((128,), dtype=float32, min=-1.019, max=1.494, mean=0.062)},\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m                                           'type': 'SampleBatch'}},\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m   'type': 'MultiAgentBatch'}\n",
            "\u001b[2m\u001b[36m(pid=10961)\u001b[0m \n",
            "Result for PPO_Pioneer-v1_d19f3_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-16_04-50-25\n",
            "  done: false\n",
            "  episode_len_mean: 500.0\n",
            "  episode_reward_max: 85.25256604263164\n",
            "  episode_reward_mean: 82.74076735478118\n",
            "  episode_reward_min: 79.07724041376439\n",
            "  episodes_this_iter: 16\n",
            "  episodes_total: 16\n",
            "  experiment_id: 4c16605f59d24b9c9528154f726125bb\n",
            "  hostname: 0deed4a924c2\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        allreduce_latency: 0.0\n",
            "        cur_kl_coeff: 0.1999999999999999\n",
            "        cur_lr: 2.000000000000001e-05\n",
            "        entropy: 4.26138026373727\n",
            "        entropy_coeff: 0.0\n",
            "        kl: 0.003769218008817425\n",
            "        policy_loss: -0.010987271155629839\n",
            "        total_loss: 12.768540701222799\n",
            "        vf_explained_var: 0.46454501152038574\n",
            "        vf_loss: 12.778773823427775\n",
            "    num_steps_sampled: 8000\n",
            "    num_steps_trained: 8000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 64.81829268292684\n",
            "    ram_util_percent: 16.11422764227643\n",
            "  pid: 10961\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.14820955288647086\n",
            "    mean_env_wait_ms: 17.068728493565455\n",
            "    mean_inference_ms: 1.785875871589431\n",
            "    mean_raw_obs_processing_ms: 0.41918515592884265\n",
            "  time_since_restore: 179.4847273826599\n",
            "  time_this_iter_s: 179.4847273826599\n",
            "  time_total_s: 179.4847273826599\n",
            "  timers:\n",
            "    learn_throughput: 335.353\n",
            "    learn_time_ms: 23855.473\n",
            "    sample_throughput: 51.408\n",
            "    sample_time_ms: 155617.603\n",
            "    update_time_ms: 3.177\n",
            "  timestamp: 1618548625\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 8000\n",
            "  training_iteration: 1\n",
            "  trial_id: d19f3_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 2/1024 (1 PENDING, 1 RUNNING)\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                 | status   | loc              | entropy_coeff_schedule                    |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|----------------------------+----------+------------------+-------------------------------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  | 172.28.0.2:10961 | [(0, 0.040703605516862085), (1000000, 0)] |      1 |          179.485 | 8000 |  82.7408 |              85.2526 |              79.0772 |                500 |\n",
            "| PPO_Pioneer-v1_d19f3_00001 | PENDING  |                  | [(0, 0.00753184978151902), (1000000, 0)]  |        |                  |      |          |                      |                      |                    |\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_Pioneer-v1_d19f3_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-16_04-51-57\n",
            "  done: false\n",
            "  episode_len_mean: 486.78125\n",
            "  episode_reward_max: 98.7986881141688\n",
            "  episode_reward_mean: 82.63024846768715\n",
            "  episode_reward_min: 77.92419081173801\n",
            "  episodes_this_iter: 16\n",
            "  episodes_total: 32\n",
            "  experiment_id: 4c16605f59d24b9c9528154f726125bb\n",
            "  hostname: 0deed4a924c2\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        allreduce_latency: 0.0\n",
            "        cur_kl_coeff: 0.09999999999999995\n",
            "        cur_lr: 2.000000000000001e-05\n",
            "        entropy: 4.352113375588069\n",
            "        entropy_coeff: 0.04037797667272717\n",
            "        kl: 0.011445041568506332\n",
            "        policy_loss: -0.017767163303991158\n",
            "        total_loss: 12.101876994920156\n",
            "        vf_explained_var: 0.5346646904945374\n",
            "        vf_loss: 12.29422932957846\n",
            "    num_steps_sampled: 16000\n",
            "    num_steps_trained: 16000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.246031746031754\n",
            "    ram_util_percent: 15.822222222222228\n",
            "  pid: 10961\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.14587029602637352\n",
            "    mean_env_wait_ms: 14.387553446127967\n",
            "    mean_inference_ms: 1.7579943788645997\n",
            "    mean_raw_obs_processing_ms: 0.3893893165565116\n",
            "  time_since_restore: 270.9687798023224\n",
            "  time_this_iter_s: 91.48405241966248\n",
            "  time_total_s: 270.9687798023224\n",
            "  timers:\n",
            "    learn_throughput: 336.929\n",
            "    learn_time_ms: 23743.883\n",
            "    sample_throughput: 71.602\n",
            "    sample_time_ms: 111728.582\n",
            "    update_time_ms: 2.983\n",
            "  timestamp: 1618548717\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 16000\n",
            "  training_iteration: 2\n",
            "  trial_id: d19f3_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 2/1024 (1 PENDING, 1 RUNNING)\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                 | status   | loc              | entropy_coeff_schedule                    |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  | 172.28.0.2:10961 | [(0, 0.040703605516862085), (1000000, 0)] |      2 |          270.969 | 16000 |  82.6302 |              98.7987 |              77.9242 |            486.781 |\n",
            "| PPO_Pioneer-v1_d19f3_00001 | PENDING  |                  | [(0, 0.00753184978151902), (1000000, 0)]  |        |                  |       |          |                      |                      |                    |\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_Pioneer-v1_d19f3_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-16_04-52-43\n",
            "  done: false\n",
            "  episode_len_mean: 491.1875\n",
            "  episode_reward_max: 98.7986881141688\n",
            "  episode_reward_mean: 82.50835383353926\n",
            "  episode_reward_min: 77.92419081173801\n",
            "  episodes_this_iter: 16\n",
            "  episodes_total: 48\n",
            "  experiment_id: 4c16605f59d24b9c9528154f726125bb\n",
            "  hostname: 0deed4a924c2\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        allreduce_latency: 0.0\n",
            "        cur_kl_coeff: 0.09999999999999995\n",
            "        cur_lr: 2.000000000000001e-05\n",
            "        entropy: 4.49271619887579\n",
            "        entropy_coeff: 0.0400523478285923\n",
            "        kl: 0.022412283582583306\n",
            "        policy_loss: -0.018285196111907088\n",
            "        total_loss: 9.470859581988956\n",
            "        vf_explained_var: 0.6753172874450684\n",
            "        vf_loss: 9.666847511416389\n",
            "    num_steps_sampled: 24000\n",
            "    num_steps_trained: 24000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 57.8171875\n",
            "    ram_util_percent: 15.400000000000002\n",
            "  pid: 10961\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.14446021944789197\n",
            "    mean_env_wait_ms: 12.288187169018554\n",
            "    mean_inference_ms: 1.7380275551805786\n",
            "    mean_raw_obs_processing_ms: 0.36495141634117084\n",
            "  time_since_restore: 317.72860455513\n",
            "  time_this_iter_s: 46.75982475280762\n",
            "  time_total_s: 317.72860455513\n",
            "  timers:\n",
            "    learn_throughput: 337.119\n",
            "    learn_time_ms: 23730.517\n",
            "    sample_throughput: 97.362\n",
            "    sample_time_ms: 82167.328\n",
            "    update_time_ms: 3.084\n",
            "  timestamp: 1618548763\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 24000\n",
            "  training_iteration: 3\n",
            "  trial_id: d19f3_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 2/1024 (1 PENDING, 1 RUNNING)\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                 | status   | loc              | entropy_coeff_schedule                    |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  | 172.28.0.2:10961 | [(0, 0.040703605516862085), (1000000, 0)] |      3 |          317.729 | 24000 |  82.5084 |              98.7987 |              77.9242 |            491.188 |\n",
            "| PPO_Pioneer-v1_d19f3_00001 | PENDING  |                  | [(0, 0.00753184978151902), (1000000, 0)]  |        |                  |       |          |                      |                      |                    |\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_Pioneer-v1_d19f3_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-16_04-54-07\n",
            "  done: false\n",
            "  episode_len_mean: 493.390625\n",
            "  episode_reward_max: 98.7986881141688\n",
            "  episode_reward_mean: 82.33252983420869\n",
            "  episode_reward_min: 76.83183102059488\n",
            "  episodes_this_iter: 16\n",
            "  episodes_total: 64\n",
            "  experiment_id: 4c16605f59d24b9c9528154f726125bb\n",
            "  hostname: 0deed4a924c2\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        allreduce_latency: 0.0\n",
            "        cur_kl_coeff: 0.15000000000000008\n",
            "        cur_lr: 2.000000000000001e-05\n",
            "        entropy: 4.5442977632795065\n",
            "        entropy_coeff: 0.03972671898445737\n",
            "        kl: 0.019568373700456013\n",
            "        policy_loss: -0.009476078245493154\n",
            "        total_loss: 8.09644510017501\n",
            "        vf_explained_var: 0.742835283279419\n",
            "        vf_loss: 8.28351597653495\n",
            "    num_steps_sampled: 32000\n",
            "    num_steps_trained: 32000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.8\n",
            "    ram_util_percent: 16.17543859649123\n",
            "  pid: 10961\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.14334291062743884\n",
            "    mean_env_wait_ms: 11.072208884229896\n",
            "    mean_inference_ms: 1.7237538055163808\n",
            "    mean_raw_obs_processing_ms: 0.3489871097998989\n",
            "  time_since_restore: 401.2807307243347\n",
            "  time_this_iter_s: 83.55212616920471\n",
            "  time_total_s: 401.2807307243347\n",
            "  timers:\n",
            "    learn_throughput: 337.016\n",
            "    learn_time_ms: 23737.746\n",
            "    sample_throughput: 104.479\n",
            "    sample_time_ms: 76570.703\n",
            "    update_time_ms: 3.041\n",
            "  timestamp: 1618548847\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 32000\n",
            "  training_iteration: 4\n",
            "  trial_id: d19f3_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 2.1/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 2/1024 (1 PENDING, 1 RUNNING)\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                 | status   | loc              | entropy_coeff_schedule                    |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  | 172.28.0.2:10961 | [(0, 0.040703605516862085), (1000000, 0)] |      4 |          401.281 | 32000 |  82.3325 |              98.7987 |              76.8318 |            493.391 |\n",
            "| PPO_Pioneer-v1_d19f3_00001 | PENDING  |                  | [(0, 0.00753184978151902), (1000000, 0)]  |        |                  |       |          |                      |                      |                    |\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_Pioneer-v1_d19f3_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-16_04-55-00\n",
            "  done: false\n",
            "  episode_len_mean: 494.7125\n",
            "  episode_reward_max: 98.7986881141688\n",
            "  episode_reward_mean: 82.39676088855484\n",
            "  episode_reward_min: 76.83183102059488\n",
            "  episodes_this_iter: 16\n",
            "  episodes_total: 80\n",
            "  experiment_id: 4c16605f59d24b9c9528154f726125bb\n",
            "  hostname: 0deed4a924c2\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        allreduce_latency: 0.0\n",
            "        cur_kl_coeff: 0.15000000000000008\n",
            "        cur_lr: 2.000000000000001e-05\n",
            "        entropy: 4.600329944065639\n",
            "        entropy_coeff: 0.0394010901403225\n",
            "        kl: 0.016434489690240413\n",
            "        policy_loss: -0.013320012646357692\n",
            "        total_loss: 7.617141387765369\n",
            "        vf_explained_var: 0.7597806453704834\n",
            "        vf_loss: 7.8092542844159265\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 59.26164383561643\n",
            "    ram_util_percent: 15.605479452054798\n",
            "  pid: 10961\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.1421841752806992\n",
            "    mean_env_wait_ms: 10.111513901874762\n",
            "    mean_inference_ms: 1.7099873123116716\n",
            "    mean_raw_obs_processing_ms: 0.33753172799573283\n",
            "  time_since_restore: 454.28433203697205\n",
            "  time_this_iter_s: 53.00360131263733\n",
            "  time_total_s: 454.28433203697205\n",
            "  timers:\n",
            "    learn_throughput: 335.796\n",
            "    learn_time_ms: 23823.971\n",
            "    sample_throughput: 119.366\n",
            "    sample_time_ms: 67020.941\n",
            "    update_time_ms: 3.074\n",
            "  timestamp: 1618548900\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 5\n",
            "  trial_id: d19f3_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 2/1024 (1 PENDING, 1 RUNNING)\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                 | status   | loc              | entropy_coeff_schedule                    |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  | 172.28.0.2:10961 | [(0, 0.040703605516862085), (1000000, 0)] |      5 |          454.284 | 40000 |  82.3968 |              98.7987 |              76.8318 |            494.712 |\n",
            "| PPO_Pioneer-v1_d19f3_00001 | PENDING  |                  | [(0, 0.00753184978151902), (1000000, 0)]  |        |                  |       |          |                      |                      |                    |\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_Pioneer-v1_d19f3_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-16_04-55-48\n",
            "  done: false\n",
            "  episode_len_mean: 495.59375\n",
            "  episode_reward_max: 98.7986881141688\n",
            "  episode_reward_mean: 82.37163338829458\n",
            "  episode_reward_min: 76.83183102059488\n",
            "  episodes_this_iter: 16\n",
            "  episodes_total: 96\n",
            "  experiment_id: 4c16605f59d24b9c9528154f726125bb\n",
            "  hostname: 0deed4a924c2\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        allreduce_latency: 0.0\n",
            "        cur_kl_coeff: 0.15000000000000008\n",
            "        cur_lr: 2.000000000000001e-05\n",
            "        entropy: 4.76876619883946\n",
            "        entropy_coeff: 0.03907546129618758\n",
            "        kl: 0.013226738790907556\n",
            "        policy_loss: -0.014150386084876364\n",
            "        total_loss: 7.109777332061813\n",
            "        vf_explained_var: 0.7923459410667419\n",
            "        vf_loss: 7.308285444974899\n",
            "    num_steps_sampled: 48000\n",
            "    num_steps_trained: 48000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 57.85538461538462\n",
            "    ram_util_percent: 15.400000000000002\n",
            "  pid: 10961\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.14151139209291774\n",
            "    mean_env_wait_ms: 9.32118850164286\n",
            "    mean_inference_ms: 1.7016167460219036\n",
            "    mean_raw_obs_processing_ms: 0.32828636666364025\n",
            "  time_since_restore: 501.6896433830261\n",
            "  time_this_iter_s: 47.40531134605408\n",
            "  time_total_s: 501.6896433830261\n",
            "  timers:\n",
            "    learn_throughput: 336.008\n",
            "    learn_time_ms: 23808.979\n",
            "    sample_throughput: 133.793\n",
            "    sample_time_ms: 59794.009\n",
            "    update_time_ms: 3.063\n",
            "  timestamp: 1618548948\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 48000\n",
            "  training_iteration: 6\n",
            "  trial_id: d19f3_00000\n",
            "  \n",
            "== Status ==\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/2.54 GiB objects\n",
            "Result logdir: /data/ssd/run/pioneer/launches/exp/PPO\n",
            "Number of trials: 2/1024 (1 PENDING, 1 RUNNING)\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                 | status   | loc              | entropy_coeff_schedule                    |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_Pioneer-v1_d19f3_00000 | RUNNING  | 172.28.0.2:10961 | [(0, 0.040703605516862085), (1000000, 0)] |      6 |           501.69 | 48000 |  82.3716 |              98.7987 |              76.8318 |            495.594 |\n",
            "| PPO_Pioneer-v1_d19f3_00001 | PENDING  |                  | [(0, 0.00753184978151902), (1000000, 0)]  |        |                  |       |          |                      |                      |                    |\n",
            "+----------------------------+----------+------------------+-------------------------------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "\n",
            "Aborted!\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_m0YRg2uVo-"
      },
      "source": [
        "!rm -rf /data/ssd/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgXIavD80cry",
        "outputId": "002faf33-bd66-4b40-9ed2-d1749a39baa0"
      },
      "source": [
        "!pip install scipy"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdPEgd8swwLN"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io as inputOutput\n",
        "\n",
        "configs = np.load(\"configs/configs0.npy\")\n",
        "configs.shape\n",
        "inputOutput.savemat(\"configs.mat\",{'conf':configs})"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1ntqRCAx44t"
      },
      "source": [
        "!mkdir configs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmoVJ_dpHOe8"
      },
      "source": [
        "bbbndfsfbаddvfvnиdcd рfvfn bbndcdcbnccnnb vfcvf vf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAVdjtlhjTjB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hSCwz9m7Ufa",
        "outputId": "72ed41fa-bf4b-45bb-b2f2-a55247da8303"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feBxiFrS7MIR"
      },
      "source": [
        "!zip -r reinf_learn.zip pioneer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTdzJRJD7fll"
      },
      "source": [
        "!cp reinf_learn.zip /content/drive/MyDrive/RobotControl/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}